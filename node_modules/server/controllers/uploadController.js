import multer from 'multer';
import path from 'path';
import { parseResumeFile } from '../services/resumeParser.js';
import { HttpError } from '../utils/errors.js';

const storage = multer.diskStorage({
  destination: (req, file, cb) => cb(null, 'server/uploads'),
  filename: (req, file, cb) => {
    const base = path.parse(file.originalname).name.replace(/\s+/g, '-');
    cb(null, `${Date.now()}-${base}${path.extname(file.originalname)}`);
  }
});
const fileFilter = (req, file, cb) => {
  const ok = /pdf|docx$/i.test(file.originalname);
  if (!ok) return cb(new HttpError('Only PDF/DOCX supported', 400));
  cb(null, true);
};
export const upload = multer({ storage, fileFilter, limits: { fileSize: 5 * 1024 * 1024 } });

export const uploadResume = async (req, res, next) => {
  try {
    if (!req.file) throw new HttpError('No file uploaded', 400);
    const text = await parseResumeFile(req.file);
    res.json({ text, filename: req.file.filename });
  } catch (err) { next(err); }
};

// LinkedIn parsing safe approach: user uploads exported LinkedIn Profile PDF
export const parseLinkedIn = async (req, res, next) => {
  try {
    if (!req.file) throw new HttpError('Upload your exported LinkedIn Profile PDF', 400);
    const text = await parseResumeFile(req.file);
    res.json({ text, source: 'linkedin-pdf' });
  } catch (err) { next(err); }
};

// ⚠️ OPTIONAL (disabled) Puppeteer scraping would go here. Be aware of TOS.
